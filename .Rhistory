full <- rbind(train, test)
# check data
str(full)
# dataset dimensions
dim(full)
# Unique values per column
lapply(full, function(x) length(unique(x)))
#Check for Missing values
# Funcion funs(): Provee una forma flexible de generar un listado de nombres de funciones para la entrada de otras
#                 funciones como sunnarie_at().
# Funcion summarize_all(): Resumir múltiples columnas.
missing_values <- full %>% summarize_all(funs(sum(is.na(.))/n()))
# Funcion gather(): Hace el reverse de spread(). Gather() recolecta un conjunto de nombres de columnas y los situa en una simple columna "key". También recolecta los registros de estas columnas y ubicar los valores en una sola columna.
missing_values <- gather(missing_values, key="feature", value="missing_pct")
missing_values %>%
ggplot(aes(x=reorder(feature,-missing_pct),y=missing_pct)) +
geom_bar(stat="identity",fill="red")+
coord_flip()+theme_bw()
#Useful data quality function for missing values
checkColumn = function(df,colname){
testData = df[[colname]]
numMissing = max(sum(is.na(testData)|is.nan(testData)|testData==''),0)
if (class(testData) == 'numeric' | class(testData) == 'Date' | class(testData) == 'difftime' | class(testData) == 'integer'){
list('col' = colname,'class' = class(testData), 'num' = length(testData) - numMissing, 'numMissing' = numMissing, 'numInfinite' = sum(is.infinite(testData)), 'avgVal' = mean(testData,na.rm=TRUE), 'minVal' = round(min(testData,na.rm = TRUE)), 'maxVal' = round(max(testData,na.rm = TRUE)))
} else{
list('col' = colname,'class' = class(testData), 'num' = length(testData) - numMissing, 'numMissing' = numMissing, 'numInfinite' = NA,  'avgVal' = NA, 'minVal' = NA, 'maxVal' = NA)
}
}
checkAllCols = function(df){
resDF = data.frame()
for (colName in names(df)){
resDF = rbind(resDF,as.data.frame(checkColumn(df=df,colname=colName)))
}
resDF
}
datatable(checkAllCols(full), style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
miss_pct <- map_dbl(full, function(x) { round((sum(is.na(x)) / length(x)) * 100, 1) })
miss_pct <- miss_pct[miss_pct > 0]
data.frame(miss=miss_pct, var=names(miss_pct), row.names=NULL) %>%
ggplot(aes(x=reorder(var, -miss), y=miss)) +
geom_bar(stat='identity', fill='red') +
labs(x='', y='% missing', title='Percent missing data by feature') +
theme(axis.text.x=element_text(angle=90, hjust=1))
full <- full %>%
mutate(Age = ifelse(is.na(Age), mean(full$Age, na.rm=TRUE), Age),
`Age Group` = case_when(Age < 13 ~ "Age.0012",
Age >= 13 & Age < 18 ~ "Age.1317",
Age >= 18 & Age < 60 ~ "Age.1859",
Age >= 60 ~ "Age.60Ov"))
full$Embarked <- replace(full$Embarked, which(is.na(full$Embarked)), 'S')
names <- full$Name
title <-  gsub("^.*, (.*?)\\..*$", "\\1", names)
full$title <- title
table(title)
###MISS, Mrs, Master and Mr are taking more numbers
###Better to group Other titles into bigger basket by checking gender and survival rate to aviod any overfitting
full$title[full$title == 'Mlle']        <- 'Miss'
full$title[full$title == 'Ms']          <- 'Miss'
full$title[full$title == 'Mme']         <- 'Mrs'
full$title[full$title == 'Lady']          <- 'Miss'
full$title[full$title == 'Dona']          <- 'Miss'
## I am afraid creating a new varible with small data can causes a overfit
## However, My thinking is that combining below feauter into original variable may loss some predictive power as they are all army folks, doctor and nobel peoples
full$title[full$title == 'Capt']        <- 'Officer'
full$title[full$title == 'Col']        <- 'Officer'
full$title[full$title == 'Major']   <- 'Officer'
full$title[full$title == 'Dr']   <- 'Officer'
full$title[full$title == 'Rev']   <- 'Officer'
full$title[full$title == 'Don']   <- 'Officer'
full$title[full$title == 'Sir']   <- 'Officer'
full$title[full$title == 'the Countess']   <- 'Officer'
full$title[full$title == 'Jonkheer']   <- 'Officer'
full$FamilySize <-full$SibSp + full$Parch + 1
full$FamilySized[full$FamilySize == 1] <- 'Single'
full$FamilySized[full$FamilySize < 5 & full$FamilySize >= 2] <- 'Small'
full$FamilySized[full$FamilySize >= 5] <- 'Big'
full$FamilySized=as.factor(full$FamilySized)
##Engineer features based on all the passengers with the same ticket
ticket.unique <- rep(0, nrow(full))
tickets <- unique(full$Ticket)
for (i in 1:length(tickets)) {
current.ticket <- tickets[i]
party.indexes <- which(full$Ticket == current.ticket)
for (k in 1:length(party.indexes)) {
ticket.unique[party.indexes[k]] <- length(party.indexes)
}
}
full$ticket.unique <- ticket.unique
full$ticket.size[full$ticket.unique == 1]   <- 'Single'
full$ticket.size[full$ticket.unique < 5 & full$ticket.unique>= 2]   <- 'Small'
full$ticket.size[full$ticket.unique >= 5]   <- 'Big'
full <- full %>%
mutate(Survived = case_when(Survived==1 ~ "Yes",
Survived==0 ~ "No"))
crude_summary <- full %>%
filter(set=="train") %>%
select(PassengerId, Survived) %>%
group_by(Survived) %>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))
crude_survrate <- crude_summary$freq[crude_summary$Survived=="Yes"]
kable(crude_summary, caption="2x2 Contingency Table on Survival.", format="markdown")
ggplot(full %>% filter(set=="train"), aes(Pclass, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Class") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Sex, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Sex") +
theme_minimal()
tbl_age <- full %>%
filter(set=="train") %>%
select(Age, Survived) %>%
group_by(Survived) %>%
summarise(mean.age = mean(Age, na.rm=TRUE))
ggplot(full %>% filter(set=="train"), aes(Age, fill=Survived)) +
geom_histogram(aes(y=..density..), alpha=0.5) +
geom_density(alpha=.2, aes(colour=Survived)) +
geom_vline(data=tbl_age, aes(xintercept=mean.age, colour=Survived), lty=2, size=1) +
scale_fill_brewer(palette="Set1") +
scale_colour_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Density") +
ggtitle("Survival Rate by Age") +
theme_minimal()
ggplot(full %>% filter(set=="train" & !is.na(Age)), aes(`Age Group`, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Age Group") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(SibSp, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by SibSp") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Parch, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Parch") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Embarked, fill=Survived)) +
geom_bar(position = "fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Embarked") +
theme_minimal()
ggplot(full %>% filter(set=="train") %>% na.omit, aes(title, fill=Survived)) +
geom_bar(position="fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Title") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(full %>% filter(set=="train") %>% na.omit, aes(`FamilySize`, fill=Survived)) +
geom_bar(position="fill") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
ylab("Survival Rate") +
geom_hline(yintercept=crude_survrate, col="white", lty=2, size=2) +
ggtitle("Survival Rate by Family Group") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(full %>% filter(set=="train"), aes(Pclass, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Class") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Sex, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Sex") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Age, fill=Survived)) +
geom_histogram(aes(y=..count..), alpha=0.5) +
geom_vline(data=tbl_age, aes(xintercept=mean.age, colour=Survived), lty=2, size=1) +
scale_fill_brewer(palette="Set1") +
scale_colour_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Density") +
ggtitle("Survived by Age") +
theme_minimal()
ggplot(full %>% filter(set=="train" & !is.na(Age)), aes(`Age Group`, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Age Group") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(SibSp, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=percent) +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by SibSp") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Parch, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Parch") +
theme_minimal()
ggplot(full %>% filter(set=="train"), aes(Embarked, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Embarked") +
theme_minimal()
ggplot(full %>% filter(set=="train") %>% na.omit, aes(title, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Title") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(full %>% filter(set=="train") %>% na.omit, aes(`FamilySize`, fill=Survived)) +
geom_bar(position="stack") +
scale_fill_brewer(palette="Set1") +
scale_y_continuous(labels=comma) +
ylab("Passengers") +
ggtitle("Survived by Family Group") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
tbl_corr <- full %>%
filter(set=="train") %>%
select(-PassengerId, -SibSp, -Parch) %>%
select_if(is.numeric) %>%
cor(use="complete.obs") %>%
corrplot.mixed(tl.cex=0.85)
tbl_mosaic <- full %>%
filter(set=="train") %>%
select(Survived, Pclass, Sex, AgeGroup=`Age Group`, title, Embarked, `FamilySize`) %>%
mutate_all(as.factor)
mosaic(~Pclass+Sex+Survived, data=tbl_mosaic, shade=TRUE, legend=TRUE)
library(alluvial)
tbl_summary <- full %>%
filter(set=="train") %>%
group_by(Survived, Sex, Pclass, `Age Group`, title) %>%
summarise(N = n()) %>%
ungroup %>%
na.omit
alluvial(tbl_summary[, c(1:4)],
freq=tbl_summary$N, border=NA,
col=ifelse(tbl_summary$Survived == "Yes", "blue", "gray"),
cex=0.65,
ordering = list(
order(tbl_summary$Survived, tbl_summary$Pclass==1),
order(tbl_summary$Sex, tbl_summary$Pclass==1),
NULL,
NULL))
###lets prepare and keep data in the proper format
feauter1<-full[1:891, c("Pclass", "title","Sex","Embarked","FamilySized","ticket.size")]
## crea una vector con los valores del campo de prediccion "Survived"
response <- as.factor(train$Survived)
## Agrega el campo de predicción "Survived" al dataset feature1
feauter1$Survived=as.factor(train$Survived)
###For Cross validation purpose will keep 20% of data aside from my orginal train set
##This is just to check how well my data works for unseen data
set.seed(500)
#Genera un matrix con los indices de los registros del dataset feature1
ind=createDataPartition(feauter1$Survived,times=1,p=0.8,list=FALSE)
#Asigna el registro del vector número "ind" a train_val
train_val=feauter1[ind,]
test_val=feauter1[-ind,]
####check the proprtion of Survival rate in orginal training data, current traing and testing data
round(prop.table(table(train$Survived)*100),digits = 1)
round(prop.table(table(train_val$Survived)*100),digits = 1)
round(prop.table(table(test_val$Survived)*100),digits = 1)
##Random forest is for more better than Single tree however single tree is very easy to use and illustrate
set.seed(1234)
Model_DT=rpart(Survived~.,data=train_val,method="class")
rpart.plot(Model_DT, fallen.leaves = T, type = 2,   branch = .3, clip.right.labs = FALSE, under = TRUE )
rpart.rules(Model_DT, cover = TRUE)
###Surprise, Check out the plot,  our Single tree model is using only Title, Pclass and Ticket.size and vomited rest
###Lets Predict train data and check the accuracy of single tree
View(test_val)
View(train_val)
View(test_val)
plot(PRE_TDT, col='lightgreen")
plot(PRE_TDT, col="lightgreen")
plot(PRE_TDT, col="lightgreen")
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
confusionMatrix(PRE_TDT,train_val$Survived)
plot(PRE_TDT, col="lightgreen")
confusionMatrix(PRE_TDT,train_val$Survived)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(echo=TRUE)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
confusionMatrix(PRE_TDT,train_val$Survived)
plot(PRE_TDT, col="lightgreen")
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~.'pclass', data=train_val, method="class")
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~pclass, data=train_val,method="class")
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~Pclass, data=train_val,method="class")
rpart.plot(Model_DT, fallen.leaves = T, type = 2,   branch = .3, clip.right.labs = FALSE, under = TRUE )
rpart.rules(Model_DT, cover = TRUE)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~Pclass+FamilySized, data=train_val,method="class")
rpart.plot(Model_DT, fallen.leaves = T, type = 2,   branch = .3, clip.right.labs = FALSE, under = TRUE )
rpart.rules(Model_DT, cover = TRUE)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
confusionMatrix(PRE_TDT,train_val$Survived)
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~Pclass+FamilySized+Embarke, data=train_val,method="class")
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~Pclass+FamilySized+Embarked, data=train_val,method="class")
rpart.plot(Model_DT, fallen.leaves = T, type = 2,   branch = .3, clip.right.labs = FALSE, under = TRUE )
rpart.rules(Model_DT, cover = TRUE)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
confusionMatrix(PRE_TDT,train_val$Survived)
# Parametro para que me de patrones de información: parms = list(split="infomration"
Model_DT=rpart(Survived~., data=train_val,method="class")
rpart.plot(Model_DT, fallen.leaves = T, type = 2,   branch = .3, clip.right.labs = FALSE, under = TRUE )
rpart.rules(Model_DT, cover = TRUE)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
confusionMatrix(PRE_TDT,train_val$Survived)
set.seed(1234)
cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
index = cv.10)
train_val <- as.data.frame(train_val)
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)
rpart.rules(Model_CDT, cover = TRUE)
rpart.rules(Model_CDT$finalModel, cover = TRUE)
cPRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
confusionMatrix(PRE_VDTS,test_val$Survived)
set.seed(1234)
rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
train_val <- as.data.frame(train_val)
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)
rpart.rules(Model_CDT$finalModel, cover = TRUE)
PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
confusionMatrix(PRE_VDTS,test_val$Survived)
col_names <- names(train_val)
train_val[col_names] <- lapply(train_val[col_names] , factor)
test_val[col_names] <- lapply(test_val[col_names] , factor)
col_names <- names(train_val)
train_val[col_names] <- lapply(train_val[col_names] , factor)
test_val[col_names] <- lapply(test_val[col_names] , factor)
set.seed(1234)
rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
rf.1
varImpPlot(rf.1)
train_val1=train_val[,-4:-5]
test_val1=test_val[,-4:-5]
set.seed(1234)
rf.2 <- randomForest(x = train_val1[,-5],y=train_val1[,5], importance = TRUE, ntree = 1000)
rf.2
varImpPlot(rf.2)
set.seed(2348)
cv10_1 <- createMultiFolds(train_val1[,5], k = 10, times = 10)
ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
index = cv10_1)
set.seed(1234)
rf.5<- train(x = train_val1[,-5], y = train_val1[,5], method = "rf", tuneLength = 3,
ntree = 1000, trControl =ctrl_1)
View(ind)
View(cv10_1)
cv.10
dim(cv.10)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
index = cv.10)
view(ctrl)
train_val <- as.data.frame(train_val)
train_val[,-7]
train_val <- as.data.frame(train_val)
train_val[,-7]
view(train_val[,-7])
view(train_val)
view(train_val[,7])
view(train_val[,-7])
## train_val[,-7]: Incluye todas las columnas excepto la columna 7 que es en este caso el campo objetivo - Survived
## train_val[,-7]: Solo incluye la columna 7, en este caso el campo objetivo - Survived
## metodo: rpart
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
## train_val[,-7]: Incluye todas las columnas excepto la columna 7 que es en este caso el campo objetivo - Survived
## train_val[,-7]: Solo incluye la columna 7, en este caso el campo objetivo - Survived
## metodo: rpart
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
trControl = ctrl)
rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)
rpart.rules(Model_CDT$finalModel, cover = TRUE)
View(ctrl)
View(ctrl)
View(Model_CDT)
View(Model_CDT)
PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
confusionMatrix(PRE_VDTS,test_val$Survived)
# Revisar en la función de predicción se debe realizar con los datos de test_val (de prueba)
PRE_TDT=predict(Model_DT,data=train_val,type="class")
plot(PRE_TDT, col="lightgreen")
confusionMatrix(PRE_TDT,train_val$Survived)
View(tbl_summary)
View(tbl_summary)
View(train_val)
View(full)
View(train_val)
View(train_val1)
View(rf.2)
knitr::opts_chunk$set(echo=TRUE)
rf.2
varImpPlot(rf.2)
library(tidyverse)
library(forcats)
library(stringr)
library(caTools)
library(DT)
library(data.table)
library(pander)
library(ggplot2)
library(scales)
library(grid)
library(gridExtra)
library(corrplot)
library(VIM)
library(knitr)
library(vcd)
library(caret)
library(xgboost)
library(MLmetrics)
library('randomForest')
library('rpart')
library('rpart.plot')
library('car')
library('e1071')
library(vcd)
library(ROCR)
library(pROC)
library(VIM)
library(glmnet)
View(rf.2)
set.seed(1234)
rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
rf.1
varImpPlot(rf.2)
train_val
view(rf.1)
view(rf.1)
View(rf.1)
View(rf.1)
train_val1=train_val[,-4:-5]
View(test_val1)
View(test_val)
View(train_val1)
View(train_val)
knitr::opts_chunk$set(echo=TRUE)
train_val1=train_val[,-4:-5]
View(test_val1)
test_val1=test_val[,-4:-5]
View(test_val1)
traing_val1[,-5]
train_val1[,-5]
